# -*- coding: utf-8 -*-
"""Skin_Lesion_Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1po7e3_6DeXLAfV9UVd7gJ3Ho-aQ28MW4
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import PIL
from PIL import Image
import cv2
import os
import matplotlib.pyplot as plt
#from google.colab.patches import cv2_imshow
# %matplotlib inline

ground_truth = pd.read_csv('~/project/ISIC_2019_Training_GroundTruth.csv')
ground_truth.tail()

output_dir = "ISIC_2019_Augmented_Input"

import os

path = output_dir
num_images = sum([len(files) for r, d, files in os.walk(path)])
print("Number of images:", num_images)

# Initialize an empty DataFrame to store the augmented image IDs and labels
augmented_data_df = pd.DataFrame(columns=ground_truth.columns)

# List all files in the input directory
image_files = os.listdir(output_dir)
for file in image_files:
  if file.find("jpg") != -1:
   # Get the label for the image
    image_identifier = file[0:file.find("augmented")-1]
    #image_identifier = file[0:file.find("jpg")-1]
    specific_image_row = ground_truth[ground_truth['image'] == image_identifier]
    label_data = specific_image_row.drop(columns=['image']).iloc[0].to_dict()

  # Append to the DataFrame
    new_row = {"image": file}
    new_row.update(label_data)
    new_data = pd.DataFrame([new_row])
    augmented_data_df = pd.concat([augmented_data_df, new_data], ignore_index=True)

augmented_data_df = augmented_data_df.sort_values(by=['image'])
augmented_data_df

mel_df = augmented_data_df.groupby("MEL").get_group(1)
nv_df = augmented_data_df.groupby("NV").get_group(1)
bcc_df = augmented_data_df.groupby("BCC").get_group(1)
ak_df = augmented_data_df.groupby("AK").get_group(1)
bkl_df = augmented_data_df.groupby("BKL").get_group(1)
df_df = augmented_data_df.groupby("DF").get_group(1)
vasc_df = augmented_data_df.groupby("VASC").get_group(1)
scc_df = augmented_data_df.groupby("SCC").get_group(1)

num_rows1 = mel_df.shape[0]
last_20_percent1 = int(num_rows1 * 0.2)
first_70_percent1 = int(num_rows1 * 0.7)

num_rows2 = nv_df.shape[0]
last_20_percent2 = int(num_rows2 * 0.2)
first_70_percent2 = int(num_rows2 * 0.7)

num_rows3 = bcc_df.shape[0]
last_20_percent3 = int(num_rows3 * 0.2)
first_70_percent3 = int(num_rows3 * 0.7)

num_rows4 = ak_df.shape[0]
last_20_percent4 = int(num_rows4 * 0.2)
first_70_percent4 = int(num_rows4 * 0.7)

num_rows5 = bkl_df.shape[0]
last_20_percent5 = int(num_rows5 * 0.2)
first_70_percent5 = int(num_rows5 * 0.7)

num_rows6 = df_df.shape[0]
last_20_percent6 = int(num_rows6 * 0.2)
first_70_percent6 = int(num_rows6 * 0.7)

num_rows7 = vasc_df.shape[0]
last_20_percent7 = int(num_rows7 * 0.2)
first_70_percent7 = int(num_rows7 * 0.7)

num_rows8 = scc_df.shape[0]
last_20_percent8 = int(num_rows8 * 0.2)
first_70_percent8 = int(num_rows8 * 0.7)

last_20_percent_df1 = mel_df.iloc[-last_20_percent1:]
last_20_percent_df2 = nv_df.iloc[-last_20_percent2:]
last_20_percent_df3 = bcc_df.iloc[-last_20_percent3:]
last_20_percent_df4 = ak_df.iloc[-last_20_percent4:]
last_20_percent_df5 = bkl_df.iloc[-last_20_percent5:]
last_20_percent_df6 = df_df.iloc[-last_20_percent6:]
last_20_percent_df7 = vasc_df.iloc[-last_20_percent7:]
last_20_percent_df8 = scc_df.iloc[-last_20_percent8:]

first_70_percent_df1 = mel_df.iloc[:first_70_percent1]
first_70_percent_df2 = nv_df.iloc[:first_70_percent2]
first_70_percent_df3 = bcc_df.iloc[:first_70_percent3]
first_70_percent_df4 = ak_df.iloc[:first_70_percent4]
first_70_percent_df5 = bkl_df.iloc[:first_70_percent5]
first_70_percent_df6 = df_df.iloc[:first_70_percent6]
first_70_percent_df7 = vasc_df.iloc[:first_70_percent7]
first_70_percent_df8 = scc_df.iloc[:first_70_percent8]

test_1 = mel_df.iloc[first_70_percent1:-last_20_percent1]
test_2 = nv_df.iloc[first_70_percent2:-last_20_percent2]
test_3 = bcc_df.iloc[first_70_percent3:-last_20_percent3]
test_4 = ak_df.iloc[first_70_percent4:-last_20_percent4]
test_5 = bkl_df.iloc[first_70_percent5:-last_20_percent5]
test_6 = df_df.iloc[first_70_percent6:-last_20_percent6]
test_7 = vasc_df.iloc[first_70_percent7:-last_20_percent7]
test_8 = scc_df.iloc[first_70_percent8:-last_20_percent8]

augmented_data_df = pd.concat([first_70_percent_df1, first_70_percent_df2, first_70_percent_df3, first_70_percent_df4, first_70_percent_df5, first_70_percent_df6, first_70_percent_df7, first_70_percent_df8])
augmented_test_df = pd.concat([last_20_percent_df1, last_20_percent_df2, last_20_percent_df3, last_20_percent_df4, last_20_percent_df5, last_20_percent_df6, last_20_percent_df7, last_20_percent_df8])
augmented_validation_df = pd.concat([test_1, test_2, test_3, test_4, test_5, test_6, test_7, test_8])

augmented_data_df = augmented_data_df.drop('UNK', axis=1)
augmented_validation_df = augmented_validation_df.drop('UNK', axis=1)
augmented_test_df = augmented_test_df.drop('UNK', axis=1)

from tensorflow.keras.preprocessing.image import ImageDataGenerator
datagen = ImageDataGenerator(rescale=1./255)

train_generator = datagen.flow_from_dataframe(
    dataframe=augmented_data_df,
    directory= output_dir,
    x_col="image",
    y_col=augmented_data_df.columns[1:],
    batch_size=16,
    shuffle=True,
    class_mode="raw",
    target_size=(224,224))

valid_generator = datagen.flow_from_dataframe(
    dataframe=augmented_validation_df,
    directory= output_dir,
    x_col="image",
    y_col=augmented_validation_df.columns[1:],
    batch_size=16,
    shuffle=True,
    class_mode="raw",
    target_size=(224,224))

test_generator = datagen.flow_from_dataframe(
    dataframe=augmented_test_df,
    directory= output_dir,
    x_col="image",
    y_col=augmented_validation_df.columns[1:],
    batch_size=16,
    shuffle=True,
    class_mode="raw",
    target_size=(224,224))

combined_data_df = pd.concat([augmented_data_df, augmented_validation_df])
combined_generator = datagen.flow_from_dataframe(
    dataframe=combined_data_df,
    directory= output_dir,
    x_col="image",
    y_col=combined_data_df.columns[1:],
    batch_size=16,
    shuffle=True,
    class_mode="raw",
    target_size=(224,224))

label_columns = augmented_data_df.columns[1:]  # All columns except the image column
y_train = augmented_data_df[label_columns].values

from sklearn.preprocessing import LabelEncoder
from sklearn.utils.class_weight import compute_class_weight

# Flatten y_train if necessary and encode labels
y_train_flat = y_train.argmax(axis=1)  # Only if each image has one label
le = LabelEncoder()
y_train_encoded = le.fit_transform(y_train_flat)

class_weights = compute_class_weight('balanced', classes=np.unique(y_train_encoded), y=y_train_encoded)
class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}

class_weights_dict

import tensorflow as tf
import scipy
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Activation
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import RMSprop, Adam
from tensorflow.keras.preprocessing.image import img_to_array, load_img
import numpy as np
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.layers import Dropout
from tensorflow.keras.regularizers import l2

# for tensorflow keras
from classification_models.tfkeras import Classifiers
ResNeXt50, preprocess_input = Classifiers.get('resnext50')
# Define your model architecture
base_model = ResNeXt50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
x = base_model.output
x = GlobalAveragePooling2D()(x)
"""
x = Dense(1024, activation='relu')(x)
x = BatchNormalization()(x)
x = Dropout(0.5)(x)
"""
x = Dense(512, kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)
x = BatchNormalization()(x)
x = Activation('relu')(x)
x = Dropout(0.6)(x)

predictions = Dense(8, activation='softmax')(x)
model = Model(inputs=base_model.input, outputs=predictions)

# Define the ModelCheckpoint callback to save the best model
checkpoint = ModelCheckpoint("best_model2.h5", monitor="val_accuracy", save_best_only=True, mode="max", verbose=1)
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001, verbose=1)

# Compile the model
model.compile(optimizer=RMSprop(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
num_epochs = 50
steps_per_epoch = len(train_generator)

history = model.fit(
    train_generator,
    validation_data=valid_generator,
    epochs=num_epochs,
    steps_per_epoch = steps_per_epoch,
    callbacks=[checkpoint, early_stopping, reduce_lr],  # Add the ModelCheckpoint callback
    class_weight=class_weights_dict,
)
# Calculate test loss and accuracy based on the final averaged predictions
test_loss, test_accuracy = model.evaluate(test_generator)
print(f"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}")

# Plotting loss and accuracy curves
plt.figure(figsize=(20,5))
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')

plt.subplot(1,2,2)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.savefig("model2.png")

# Load the best model for testing
best_model = tf.keras.models.load_model("best_model2.h5")

# Retrain the model using both training and validation data
best_model.compile(optimizer=RMSprop(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])

# Train the best model with train and val data again
combined_data_df = pd.concat([augmented_data_df, augmented_validation_df])
total_epochs = 15  # Set the total number of epochs for retraining
steps_per_epoch = len(combined_generator)

label_columns = combined_data_df.columns[1:]  # All columns except the image column
y_train = combined_data_df[label_columns].values
# Flatten y_train if necessary and encode labels
y_train_flat = y_train.argmax(axis=1)  # Only if each image has one label
y_train_encoded = le.fit_transform(y_train_flat)

class_weights = compute_class_weight('balanced', classes=np.unique(y_train_encoded), y=y_train_encoded)
class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}

best_model.fit(
    combined_generator,
    epochs=total_epochs,
    steps_per_epoch=steps_per_epoch,
    class_weight=class_weights_dict,
)

# Calculate test loss and accuracy based on the final averaged predictions
test_loss, test_accuracy = best_model.evaluate(test_generator)
print(f"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}")